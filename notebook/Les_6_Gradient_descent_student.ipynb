{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent  - opgaven\n",
    "\n",
    "In dit notebook staan een aantal opgaven die als doel hebben de werking van *gradient descent* te leren begrijpen. Het gradient descent algoritme heeft als doel het stapsgewijs vinden van een / de minimumwaarde van een functie. We zullen het algoritme handmatig toepassen en het algoritme implementeren in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deel I. Simpele kwadratische functie\n",
    "\n",
    "Gegeven de functie:\n",
    "\n",
    "$$ f_1(x) = {x^2} $$\n",
    "\n",
    "Voor deze functie is het eenvoudig om de minimumwaarde te vinden: $x=0$ geeft het minimum $f_1(x) = 0$. Er zijn verschillende manieren om dat minimum te vinden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotten\n",
    "In onderstaande plot kun je in één oogopslag het minimum zien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functie voor f1(x)\n",
    "def f1(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input en output f1(x) bepalen\n",
    "x = np.linspace(-5,5,1000) \n",
    "y = f1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input en output f1(x) plotten\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afgeleide berekenen\n",
    "\n",
    "In een grafiek kun je niet altijd precies de waardes aflezen. Je kunt in dat geval de afgeleide gebruiken: daar waar de afgeleide 0 is, is er sprake van een maximum, een zadelpunt of een minimum.\n",
    "\n",
    "De afgeleide van $f_1(x)$ is simpel te bepalen:\n",
    "\n",
    "$$ f_1'(x) = {2x} $$\n",
    "\n",
    "Door vervolgens de vergelijking $f_1'(x) = 0$ op te lossen, vind je het (in dit geval) minimum:\n",
    "\n",
    "\\begin{align}\n",
    "    f_1'(x) &= 0  \\\\\n",
    "    2x &= 0       \\\\\n",
    "    x &= 0\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "Helaas is het leven niet altijd zo eenvoudig. Functies met meer dan drie variabelen kun je niet plotten en berekenen waar de afgeleide van een functie 0 is, is vaak niet haalbaar. Gelukkig hebben we het gradient descent algoritme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opgave 1.\n",
    "\n",
    "Pas het gradient descent algoritme **handmatig** toe om het minimum van $f_1(x)$ te vinden voor een viertal scenario's:\n",
    "\n",
    "1. Startpunt $x = 1$ en learning rate $\\eta = 1.0$\n",
    "2. Startpunt $x = 1$ en learning rate $\\eta = 1.1$\n",
    "3. Startpunt $x = 1$ en learning rate $\\eta = 0.9$\n",
    "4. Startpunt $x = 1$ en learning rate $\\eta = 0.1$\n",
    "\n",
    "Ga als volgt te werk:\n",
    "- Bepaal de afgeleide van de functie $f'_1(x)$\n",
    "- Bepaal de gradient bij $x = 1$\n",
    "- Bepaal met behulp van het startpunt, de gradient en de learning rate het vervolgpunt\n",
    "- Ga door tot dat de gradient kleiner dan 0.1 is of totdat je 5 iteraties hebt doorlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deel II. Lokaal en globaal minimum\n",
    "\n",
    "De tweede functie is wat complexer:\n",
    "\n",
    "\\begin{equation*}\n",
    "f_2(x) = {3^x} - {x^3}\n",
    "\\end{equation*}\n",
    "\n",
    "In onderstaande grafieken is te zien dat er twee minima zijn: een lokaal minimum en een globaal minimum. In de grafieken is niet te zien wat de exacte waarde voor `x` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functie voor f2(x)\n",
    "def f2(x):\n",
    "    return 3**x - x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input en output voor f2(x) bepalen\n",
    "x = np.linspace(-5,5,1000) \n",
    "y = f2(x)\n",
    "\n",
    "# Input en output plotten: complete grafiek\n",
    "plt.figure(figsize=(8,6), dpi=100)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input en output plotten: inzoomen op minima\n",
    "plt.figure(figsize=(8,6), dpi=100)\n",
    "ax = plt.axes()\n",
    "ax.set(xlim=(-1,5), ylim=(-1, 3))\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opgave 2.\n",
    "\n",
    "Pas het gradient descent algoritme **handmatig** toe om *een* minimum van $f_2(x)$ te vinden voor een aantal scenario's:\n",
    "1. Startpunt $x = 4$ en learning rate $\\eta = 0.10$\n",
    "2. Startpunt $x = 4$ en learning rate $\\eta = 0.05$\n",
    "\n",
    "Ga als volgt te werk:\n",
    "- Bepaal de afgeleide van de functie $f_2(x)$\n",
    "- Bepaal de gradient voor $x = 4$\n",
    "- Bepaal met behulp van het startpunt, de gradient en de learning rate het vervolgpunt\n",
    "- Ga door tot dat de gradient kleiner dan 0.1 is of tot dat je 5 iteraties hebt doorlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opgave 3.\n",
    "\n",
    "Schrijf code voor het gradient descent algoritme. Pas de code toe op de hierboven genoemde scenario's.\n",
    "\n",
    "Ga als volgt te werk:\n",
    "- Schrijf een functie `df2(x)` voor $f'_2(x)$ die als input een waarde `x` krijgt en als output `y` geeft\n",
    "- Schrijf een functie `gd_f2(x, eta)` voor gradient descent voor $f_2(x)$ die als input een startpunt `x` en learning rate `eta` krijgt en als returnwaarde `(path_x, path_y)` de *paden* van zowel `x` als `y` geeft. De returnwaarde `path_x` ziet er bijvoorbeeld zo uit na 4 iteraties met startpunt `x = 4`: `path_x = [4, 3, 2, 1, 0]`.\n",
    "- Maar stel eerst **pseudocode** op! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deel III. Meerdere dimensies\n",
    "\n",
    "De derde functie bevat niet één, maar twee variabelen:\n",
    "\n",
    "\\begin{equation*}\n",
    "f_3(x_1, x_2) = {x_1^2} + {2 x_{2}^2}\n",
    "\\end{equation*}\n",
    "\n",
    "Het is simpel in te zien dat het minimum bij $f_3(0, 0)$ ligt. Het is hieronder ook te zien:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(x1, x2):\n",
    "    return x1**2 + 2*x2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.linspace(-5,5,10) \n",
    "x2 = np.linspace(-5,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((len(x1),len(x2)))\n",
    "for a in range(0,len(x1)):\n",
    "    for b in range(0,len(x2)):\n",
    "        y[a][b] = f3(x1[a], x2[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.contour3D(x1, x2, y, 50, cmap='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelfde figuur, maar dan recht van boven\n",
    "ax.view_init(90, 0)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opgave 4.\n",
    "\n",
    "Pas het gradient descent algoritme **handmatig** toe om *een* minimum van $f_3(x_1, x_2) = {x_1^2} + {2 x_{2}^2}$ te vinden voor onderstaande scenario's:\n",
    "- Startpunt $(x_1, x_2) = (-4, 4)$, learning rate $\\eta = 0.4$\n",
    "- Startpunt $(x_1, x_2) = (-4, 4)$, learning rate $\\eta = 0.04$\n",
    "\n",
    "Ga als volgt te werk:\n",
    "- Bepaal de partieel afgeleides van $f_3(x_1, x_2)$ voor $x_1$ en $x_2$, dus:\n",
    "\n",
    "$$ \\frac{\\partial f_3}{\\partial x_1} \\text{ en } \\frac{\\partial f_3}{\\partial x_2} $$ \n",
    "\n",
    "- Bepaal de gradients voor zowel $x_1$ als $x_2$ voor het gegeven startpunt\n",
    "- Bepaal met behulp van het startpunt, de gradient en de learning rate het vervolgpunt\n",
    "- Ga door tot dat de gradient kleiner dan 0.1 is of tot dat je 5 iteraties hebt doorlopen\n",
    "\n",
    "NB. Let op het verschil tussen de stappen die gemaakt worden voor $x_1$ en $x_2$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deel IV. De eindbaas\n",
    "\n",
    "De *Bowser* van onze functies ziet er als volgt uit:\n",
    "\n",
    "\\begin{equation*}\n",
    "f_{4}(x_1, x_2) = {3^{x_1}} - {x_1^3} + {3^{x_2}} - {x_2^3}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f4(x1, x2):\n",
    "    return 3**x1 - x1**3 + 3**x2 - x2**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.linspace(-3,5,1000) \n",
    "x2 = np.linspace(-3,5,1000)\n",
    "\n",
    "y = np.zeros((len(x1),len(x2)))\n",
    "for a in range(0,len(x1)):\n",
    "    for b in range(0,len(x2)):\n",
    "        y[a][b] = f4(x1[a], x2[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.contour3D(x1, x2, y, 50, cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De beperkingen van de 3D plots van Matplotlib komen hier aan het licht, vandaar dat we Holoviews gebruiken voor deze functie. Het laden van de grafiek kan even duren, maar je kunt daarna zien dat de bodem niet vlak is maar glooiend is. Er is dus sprake van meerdere (lokale én globale) minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importeer holoviews en plotly eerst\n",
    "import holoviews as hv\n",
    "hv.extension('plotly')\n",
    "surface = hv.Surface(y, bounds=(-5, -5, 5, 5))\n",
    "surface.opts(width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opgave 5.  (optioneel)\n",
    "\n",
    "Pas het gradient descent algoritme **handmatig** toe om *een* minimum van $f_{4}(x_1, x_2) = {3^{x_1}} - {x_1^3} + {3^{x_2}} - {x_2^3}$ te vinden voor de volgende scenario's:\n",
    "\n",
    "- Startpunt $(x_1, x_2) = (2, 1)$, learning rate $\\eta = 0.5$\n",
    "- Startpunt $(x_1, x_2) = (2, 1)$, learning rate $\\eta = 0.05$\n",
    "\n",
    "Ga als volgt te werk:\n",
    "\n",
    "- Bepaal de afgeleides van $f_4(x_1, x_2)$\n",
    "- Bepaal de gradient op $(x_1, x_2) = (2, 1)$\n",
    "- Bepaal met behulp van het startpunt, de gradient en de learning rate het vervolgpunt\n",
    "- Ga door tot dat de gradient kleiner dan 0.1 is of tot dat je 5 iteraties hebt doorlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opgave 6. (optioneel)\n",
    "\n",
    "Breid de code voor het gradient descent algoritme uit om te kunnen werken met twee inputvariabelen. Pas de code toe op de hierboven genoemde scenario's.\n",
    "\n",
    "Ga als volgt te werk:\n",
    "- Schrijf voor beide afgeleides van $f_4(x_1, x_2)$ een functie die respectievelijk als input een waarde `x1` of `x2` krijgt en als output `y` geeft\n",
    "- Schrijf een functie `gd_f4(x1, x2, eta)` voor gradient descent voor $f_4(x_1, x_2)$ die als input twee startpunten `x1` en `x2` en een learning rate `eta` krijgt en als returnwaarde `(path_x1, path_x2, path_y)` geeft. \n",
    "- Maar stel eerst **pseudocode** op! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
